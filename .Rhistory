library(ggplot2)      # Data visualization
library(tidyr)        # Data tidying
library(RColorBrewer) # Color palettes for visualizations
library(leaflet)      # Interactive maps
library(shiny)        # Building interactive web applications
library(leaflet.extras) # Additional features for leaflet maps
library(corrplot)     # Visualization of correlation matrices
library(mice)         # Handling missing data
library(nnet)         # Multinomial regression model
library(forcats)      # Handling categorical variables
library(patchwork)    # Combining multiple ggplots
library(VGAM)         # Multinomial logistic regression models
library(tidyverse)    # Collection of data science packages
library(e1071)        # Support Vector Machines (SVM)
library(reshape2)     # Data reshaping for ggplot visualizations
library(caret)        # Machine learning and model evaluation
# import the dataset
BCN_Accomm_full <- read.csv("Cleaned_airbnb_barcelona.csv")
# Structure
glimpse(BCN_Accomm_full)
set.seed(100)
BCN_Accomm_sub <- sample_n(BCN_Accomm_full, 10000)
glimpse(BCN_Accomm_sub)
BCN_Accomm_sub$price <- gsub(",", "", BCN_Accomm_sub$price) # removed ','
BCN_Accomm_sub$price <- gsub("\\$", "", BCN_Accomm_sub$price) # removed '$' sign
BCN_Accomm_sub$price <- as.numeric(BCN_Accomm_sub$price)  # converted to number format
BCN_Accomm_sub$price <- gsub(",", "", BCN_Accomm_sub$price) # removed ','
BCN_Accomm_sub$price <- gsub("\\$", "", BCN_Accomm_sub$price) # removed '$' sign
BCN_Accomm_sub$price <- as.numeric(BCN_Accomm_sub$price)  # converted to number format
# converting categorical variables into factors
BCN_Accomm$neighbourhood <- as.factor(BCN_Accomm$neighbourhood)
# converting categorical variables into factors
BCN_Accomm_sub$neighbourhood <- as.factor(BCN_Accomm_sub$neighbourhood)
BCN_Accomm_sub$property_type <- as.factor(BCN_Accomm_sub$property_type)
BCN_Accomm_sub$room_type <- as.factor(BCN_Accomm_sub$room_type)
BCN_Accomm_sub$zipcode <- as.factor(BCN_Accomm_sub$zipcode)
BCN_Accomm_sub$availability_30 <- as.factor(BCN_Accomm_sub$availability_30)
BCN_Accomm_sub$accommodates <- as.factor(BCN_Accomm_sub$accommodates)
# Create a new data frame with the imputed review_scores_rating column
imp_BCN_Accomm_sub <- BCN_Accomm_sub %>%
mutate(review_scores_rating = if_else(is.na(review_scores_rating), 0, review_scores_rating))
md.pattern(imp_BCN_Accomm_sub, rotate.names = TRUE)
BCN_Accomm <- na.omit(imp_BCN_Accomm_sub) # from this point we'll use this data set
md.pattern(BCN_Accomm, rotate.names = TRUE)
# include price - use CR
# Create a correlation matrix for numeric fields
cor_BNC_Accomm <- select_if(BCN_Accomm, is.numeric) %>%
select(-c(id, X, host_id))
# make a data frame
cor_BNC_Accomm <- data.frame(cor_BNC_Accomm)
str(cor_BNC_Accomm)
# print correlation matrix
corrplot(cor(cor_BNC_Accomm), type = "upper", order = "hclust", tl.col = "black")
# Calculate Q1, Q3, and IQR for the price variable
Q1 <- quantile(BCN_Accomm$price, 0.25)
Q3 <- quantile(BCN_Accomm$price, 0.75)
IQR <- Q3 - Q1
# Add a column to indicate outliers
BCN_Accomm_sub_outlier <- BCN_Accomm %>%
mutate(is_outlier = price < (Q1 - 1.5 * IQR) | price > (Q3 + 1.5 * IQR))
# Count the number of outliers
outliers_count <- sum(BCN_Accomm_sub_outlier$is_outlier)
# Display outliers count
outliers_count
# Boxplot for price variable
boxplot(BCN_Accomm$price,
horizontal = TRUE,
axes = FALSE,
staplewex = 1,
ylim = c(2, 500),
main = "Boxplot of Price/Night Variable (€)")
# X Axis
axis(1, las = 1)
# Add text labels values (Q1, Q3, IQR)
stats <- boxplot.stats(BCN_Accomm$price)$stats
text(x = stats, y = 1.25, labels = stats, pos = 3, cex = 0.9)
# Filter rows Outliers
outlier_extremes <- BCN_Accomm_sub_outlier%>%
filter(is_outlier == TRUE) %>%
select(neighbourhood, property_type, bedrooms, price) %>%
arrange(desc(price), neighbourhood, property_type) %>%
slice_head(n = 20)  # Select top 20 Outliers for price
# Display Prices outliers
knitr::kable(outlier_extremes,
caption = "Table 2: Top 20 and Outliers for Price Variable with Neighbourhood",
align = "c")
# Filter dataset
BCN_Accomm <- BCN_Accomm %>%
filter(price <= 1000)
glimpse(BCN_Accomm_sub)
# Filter dataset
BCN_Accomm <- BCN_Accomm %>%
filter(price <= 1000)
summary(BCN_Accomm_sub$price)
# Filter dataset
BCN_Accomm <- BCN_Accomm %>%
filter(price <= 1000)
summary(BCN_Accomm_sub$price)
# Filter dataset
BCN_Accomm <- BCN_Accomm %>%
filter(price <= 1000)
summary(BCN_Accomm$price)
# converting categorical variables into factors
BCN_Accomm_sub$neighbourhood <- as.factor(BCN_Accomm_sub$neighbourhood)
BCN_Accomm_sub$property_type <- as.factor(BCN_Accomm_sub$property_type)
BCN_Accomm_sub$room_type <- as.factor(BCN_Accomm_sub$room_type)
BCN_Accomm_sub$zipcode <- as.factor(BCN_Accomm_sub$zipcode)
BCN_Accomm_sub$availability_30 <- as.factor(BCN_Accomm_sub$availability_30)
BCN_Accomm_sub$accommodates <- as.factor(BCN_Accomm_sub$accommodates)
BCN_Accomm_sub$price <- as.factor(BCN_Accomm_sub$price)
options(repos = c(CRAN = "https://cran.rstudio.com/"))
#file.edit("~/.Rprofile")
knitr::opts_chunk$set(echo = TRUE)
#options(repos = c(CRAN = "https://cran.rstudio.com/"))
knitr::include_graphics("Barcelona Picture.png")
# Load required libraries
library(dplyr)        # Data manipulation and wrangling
library(ggplot2)      # Data visualization
library(tidyr)        # Data tidying
library(RColorBrewer) # Color palettes for visualizations
library(leaflet)      # Interactive maps
library(shiny)        # Building interactive web applications
library(leaflet.extras) # Additional features for leaflet maps
library(corrplot)     # Visualization of correlation matrices
library(mice)         # Handling missing data
library(nnet)         # Multinomial regression model
library(forcats)      # Handling categorical variables
library(patchwork)    # Combining multiple ggplots
library(VGAM)         # Multinomial logistic regression models
library(tidyverse)    # Collection of data science packages
library(e1071)        # Support Vector Machines (SVM)
library(reshape2)     # Data reshaping for ggplot visualizations
library(caret)        # Machine learning and model evaluation
# import the dataset
BCN_Accomm_full <- read.csv("Cleaned_airbnb_barcelona.csv")
# Structure
glimpse(BCN_Accomm_full)
set.seed(100)
BCN_Accomm_sub <- sample_n(BCN_Accomm_full, 10000)
glimpse(BCN_Accomm_sub)
BCN_Accomm_sub$price <- gsub(",", "", BCN_Accomm_sub$price) # removed ','
BCN_Accomm_sub$price <- gsub("\\$", "", BCN_Accomm_sub$price) # removed '$' sign
BCN_Accomm_sub$price <- as.numeric(BCN_Accomm_sub$price)  # converted to number format
print('Location of missing values')
# find location of missing values column wise
sapply(BCN_Accomm_sub, function(x) which(is.na(x)))
# count the missing values column wise
sapply(BCN_Accomm_sub, function(x) sum(is.na(x)))
md.pattern(BCN_Accomm_sub, rotate.names = TRUE)
# Total observations
total_rows <- nrow(BCN_Accomm_sub)
# Calculate missing values (count and percentage)
missing_values <- data.frame(
#Variable = names(BCN_Accomm_full),
Missing_Count = colSums(is.na(BCN_Accomm_sub)),
Missing_Percent = paste0(round((colSums(is.na(BCN_Accomm_sub)) / total_rows) * 100, 2), "%"))
# Order DataFrame table in descending order
missing_values <- missing_values[order(-missing_values$Missing_Count), ]
# Display the table
knitr::kable(missing_values,
caption = "Missing Values by Variable",
align = "c")
# Create a new data frame with the imputed review_scores_rating column
imp_BCN_Accomm_sub <- BCN_Accomm_sub %>%
mutate(review_scores_rating = if_else(is.na(review_scores_rating), 0, review_scores_rating))
md.pattern(imp_BCN_Accomm_sub, rotate.names = TRUE)
BCN_Accomm <- na.omit(imp_BCN_Accomm_sub) # from this point we'll use this data set
md.pattern(BCN_Accomm, rotate.names = TRUE)
# include price - use CR
# Create a correlation matrix for numeric fields
cor_BNC_Accomm <- select_if(BCN_Accomm, is.numeric) %>%
select(-c(id, X, host_id))
# make a data frame
cor_BNC_Accomm <- data.frame(cor_BNC_Accomm)
str(cor_BNC_Accomm)
# print correlation matrix
corrplot(cor(cor_BNC_Accomm), type = "upper", order = "hclust", tl.col = "black")
# Calculate Q1, Q3, and IQR for the price variable
Q1 <- quantile(BCN_Accomm$price, 0.25)
Q3 <- quantile(BCN_Accomm$price, 0.75)
IQR <- Q3 - Q1
# Add a column to indicate outliers
BCN_Accomm_sub_outlier <- BCN_Accomm %>%
mutate(is_outlier = price < (Q1 - 1.5 * IQR) | price > (Q3 + 1.5 * IQR))
# Count the number of outliers
outliers_count <- sum(BCN_Accomm_sub_outlier$is_outlier)
# Display outliers count
outliers_count
# Boxplot for price variable
boxplot(BCN_Accomm$price,
horizontal = TRUE,
axes = FALSE,
staplewex = 1,
ylim = c(2, 500),
main = "Boxplot of Price/Night Variable (€)")
# X Axis
axis(1, las = 1)
# Add text labels values (Q1, Q3, IQR)
stats <- boxplot.stats(BCN_Accomm$price)$stats
text(x = stats, y = 1.25, labels = stats, pos = 3, cex = 0.9)
# Filter rows Outliers
outlier_extremes <- BCN_Accomm_sub_outlier%>%
filter(is_outlier == TRUE) %>%
select(neighbourhood, property_type, bedrooms, price) %>%
arrange(desc(price), neighbourhood, property_type) %>%
slice_head(n = 20)  # Select top 20 Outliers for price
# Display Prices outliers
knitr::kable(outlier_extremes,
caption = "Table 2: Top 20 and Outliers for Price Variable with Neighbourhood",
align = "c")
# Filter dataset
BCN_Accomm <- BCN_Accomm %>%
filter(price <= 1000)
summary(BCN_Accomm$price)
# Reshape the data set to long format
BCN_Accomm_hist <- BCN_Accomm %>%
pivot_longer(cols = c(price,
accommodates,
bathrooms,
bedrooms,
beds,
minimum_nights,
number_of_reviews_ltm,
review_scores_rating
),
names_to = "variable", values_to = "value")
# Create histograms with facet_wrap
hist_num <- ggplot(BCN_Accomm_hist, aes(x = value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
labs(title = "Histograms for Numerical Variables", x = "Value", y = "Frequency") +
facet_wrap(~variable, scales = "free") +  # each plot with their own y axes
theme_minimal()
print(hist_num)
# Calculate percentages and relabel values
superhost_data <- BCN_Accomm %>%
count(host_is_superhost) %>%
mutate(
percentage = n / sum(n) * 100,  # Calculate percentages
host_is_superhost = recode(host_is_superhost, "f" = "False", "t" = "True")  # Relabel
)
# Create the pie chart with percentages
pc_sh_status <- ggplot(superhost_data, aes(x = "", y = n, fill = host_is_superhost)) +
geom_col() +
coord_polar(theta = "y") +
geom_text(aes(label = paste0(round(percentage, 1), "%")), position = position_stack(vjust = 0.5)) +  # Add percentages
labs(
title = "Proportion of Superhost Status",
fill = "Superhost Status\n(False = Not a Superhost, True = Superhost)"
) +
theme_void() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),  # Center and bold title
legend.title = element_text(size = 10),
legend.text = element_text(size = 9)
)
print(pc_sh_status)
# Filter for the top 10 property types and calculate percentages
top_property_types <- BCN_Accomm %>%
count(property_type, sort = TRUE) %>%
slice_max(n, n = 10) %>%  # Keep the top 10 most frequent property types
mutate(percentage = n / sum(n) * 100)  # Calculate percentages
# Create the bar plot with percentages and labels
top_property <- ggplot(top_property_types, aes(x = reorder(property_type, percentage), y = percentage, fill = property_type)) +
geom_col() +
geom_text(aes(label = paste0(round(percentage, 1))), hjust = -0.2, size = 4) +  # Add percentage labels
coord_flip() +  # Flip coordinates for better readability
labs(title = "Top 10 Property Types by Percentage", x = "Property Type", y = "Percentage (%)") +
theme_minimal() +
theme(
legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold"))  # Center and bold title)
print(top_property)
# Reshape the dataset to long format
BCN_Accomm_long <- BCN_Accomm %>%
pivot_longer(cols = c(room_type), names_to = "variable", values_to = "value")
# Calculate the percentage for each category within the room_type variable
BCN_Accomm_percentage <- BCN_Accomm_long %>%
group_by(variable, value) %>%
summarize(count = n()) %>%
mutate(percentage = count / sum(count) * 100)
# Create a barplot
room_type_plot <- ggplot(BCN_Accomm_percentage, aes(x = value, y = percentage, fill = variable)) +
geom_bar(stat = "identity") +
labs(title = "Percentage Barplot for Room Type", x = "Category", y = "Percentage (%)") +
theme_minimal() +
theme(
legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold"))
print(room_type_plot)
# Filter for the top 10 neighbourhoods and calculate percentages
top_neighbourhoods <- BCN_Accomm %>%
count(neighbourhood, sort = TRUE) %>%
slice_max(n, n = 10) %>%
mutate(percentage = n / sum(n) * 100)  # Calculate percentages
# Create the plot with percentages and labels
top_neighbourhoods <- ggplot(top_neighbourhoods, aes(x = reorder(neighbourhood, percentage), y = percentage, fill = neighbourhood)) +
geom_col() +
geom_text(aes(label = paste0(round(percentage, 1))), hjust = -0.2, size = 4) +  # Add percentage labels
coord_flip() +
labs(title = "Top 10 Neighbourhoods by Percentage", x = "Neighbourhood", y = "Percentage (%)") +
theme_minimal() +
theme(
legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold"))
print(top_neighbourhoods)
# Combine all amenities into a single text string and clean it
amenities_text <- BCN_Accomm$amenities %>%
paste(collapse = " ") %>%                # Combine all rows into one string
gsub("\\[|\\]|'", "", .)                 # Remove brackets and quotes from the field
# Split the text into words and calculate word frequencies
word_freq <- table(unlist(strsplit(amenities_text, ", ")))
# Create the word cloud
wordcloud(words = names(word_freq),
freq = as.numeric(word_freq),
min.freq = 10,                   # Minimum frequency for words to appear
scale = c(3, 0.5),               # Word size scale
random.order = FALSE,            # Words ordered by frequency
colors = brewer.pal(8, "Dark2"))
# Load required libraries
library(dplyr)        # Data manipulation and wrangling
library(ggplot2)      # Data visualization
library(tidyr)        # Data tidying
library(RColorBrewer) # Color palettes for visualizations
library(leaflet)      # Interactive maps
library(shiny)        # Building interactive web applications
library(leaflet.extras) # Additional features for leaflet maps
library(corrplot)     # Visualization of correlation matrices
library(mice)         # Handling missing data
library(nnet)         # Multinomial regression model
library(forcats)      # Handling categorical variables
library(patchwork)    # Combining multiple ggplots
library(VGAM)         # Multinomial logistic regression models
library(tidyverse)    # Collection of data science packages
library(e1071)        # Support Vector Machines (SVM)
library(reshape2)     # Data reshaping for ggplot visualizations
library(caret)        # Machine learning and model evaluation
library(wordcloud)    # Wordcloud plot
library(rsample)      # Split dataset into training and testing
# Load required libraries
library(dplyr)        # Data manipulation and wrangling
library(ggplot2)      # Data visualization
library(tidyr)        # Data tidying
library(RColorBrewer) # Color palettes for visualizations
library(leaflet)      # Interactive maps
library(shiny)        # Building interactive web applications
library(leaflet.extras) # Additional features for leaflet maps
library(corrplot)     # Visualization of correlation matrices
library(mice)         # Handling missing data
library(nnet)         # Multinomial regression model
library(forcats)      # Handling categorical variables
library(patchwork)    # Combining multiple ggplots
library(VGAM)         # Multinomial logistic regression models
library(tidyverse)    # Collection of data science packages
library(e1071)        # Support Vector Machines (SVM)
library(reshape2)     # Data reshaping for ggplot visualizations
library(caret)        # Machine learning and model evaluation
library(wordcloud)    # Wordcloud plot
library(rsample)      # Split dataset into training and testing
library(gam)
# Load required libraries
library(dplyr)        # Data manipulation and wrangling
library(ggplot2)      # Data visualization
library(tidyr)        # Data tidying
library(RColorBrewer) # Color palettes for visualizations
library(leaflet)      # Interactive maps
library(shiny)        # Building interactive web applications
library(leaflet.extras) # Additional features for leaflet maps
library(corrplot)     # Visualization of correlation matrices
library(mice)         # Handling missing data
library(nnet)         # Multinomial regression model
library(forcats)      # Handling categorical variables
library(patchwork)    # Combining multiple ggplots
library(VGAM)         # Multinomial logistic regression models
library(tidyverse)    # Collection of data science packages
library(e1071)        # Support Vector Machines (SVM)
library(reshape2)     # Data reshaping for ggplot visualizations
library(caret)        # Machine learning and model evaluation
library(wordcloud)    # Wordcloud plot
library(rsample)      # Split dataset into training and testing
library(mgcv)         # Gam Mdels
print('Location of missing values')
# find location of missing values column wise
sapply(BCN_Accomm_sub, function(x) which(is.na(x)))
# count the missing values column wise
sapply(BCN_Accomm_sub, function(x) sum(is.na(x)))
md.pattern(BCN_Accomm_sub, rotate.names = TRUE)
print('Location of missing values')
# find location of missing values column wise
sapply(BCN_Accomm_sub, function(x) which(is.na(x)))
# count the missing values column wise
sapply(BCN_Accomm_sub, function(x) sum(is.na(x)))
md.pattern(BCN_Accomm_sub, rotate.names = TRUE)
# Total observations
total_rows <- nrow(BCN_Accomm_sub)
# Calculate missing values (count and percentage)
missing_values <- data.frame(
#Variable = names(BCN_Accomm_full),
Missing_Count = colSums(is.na(BCN_Accomm_sub)),
Missing_Percent = paste0(round((colSums(is.na(BCN_Accomm_sub)) / total_rows) * 100, 2), "%"))
# Order DataFrame table in descending order
missing_values <- missing_values[order(-missing_values$Missing_Count), ]
# Display the table
knitr::kable(missing_values,
caption = "Missing Values by Variable",
align = "c")
# Create a new data frame with the imputed review_scores_rating column
imp_BCN_Accomm_sub <- BCN_Accomm_sub %>%
mutate(review_scores_rating = if_else(is.na(review_scores_rating), 0, review_scores_rating))
md.pattern(imp_BCN_Accomm_sub, rotate.names = TRUE)
# Combine all amenities into a single text string and clean it
amenities_text <- BCN_Accomm$amenities %>%
paste(collapse = " ") %>%                # Combine all rows into one string
gsub("\\[|\\]|'", "", .)                 # Remove brackets and quotes from the field
# Split the text into words and calculate word frequencies
word_freq <- table(unlist(strsplit(amenities_text, ", ")))
# Create the word cloud
wordcloud(words = names(word_freq),
freq = as.numeric(word_freq),
min.freq = 10,                   # Minimum frequency for words to appear
scale = c(3, 0.5),               # Word size scale
random.order = FALSE,            # Words ordered by frequency
colors = brewer.pal(8, "Dark2") +
theme(legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold")))
# Combine all amenities into a single text string and clean it
amenities_text <- BCN_Accomm$amenities %>%
paste(collapse = " ") %>%                # Combine all rows into one string
gsub("\\[|\\]|'", "", .)                 # Remove brackets and quotes from the field
# Split the text into words and calculate word frequencies
word_freq <- table(unlist(strsplit(amenities_text, ", ")))
# Create the word cloud
wordcloud(words = names(word_freq),
freq = as.numeric(word_freq),
min.freq = 10,                   # Minimum frequency for words to appear
scale = c(3, 0.5),               # Word size scale
random.order = FALSE,            # Words ordered by frequency
colors = brewer.pal(8, "Dark2") +
title("Wordcloud for Amaneties") +
theme(legend.position = "none",
plot.title = element_text(hjust = 0.5, face = "bold")))
# Combine all amenities into a single text string and clean it
amenities_text <- BCN_Accomm$amenities %>%
paste(collapse = " ") %>%                # Combine all rows into one string
gsub("\\[|\\]|'", "", .)                 # Remove brackets and quotes from the field
# Split the text into words and calculate word frequencies
word_freq <- table(unlist(strsplit(amenities_text, ", ")))
# Create the word cloud
wordcloud(words = names(word_freq),
freq = as.numeric(word_freq),
min.freq = 10,                   # Minimum frequency for words to appear
scale = c(3, 0.5),               # Word size scale
random.order = FALSE,            # Words ordered by frequency
colors = brewer.pal(8, "Dark2"))
# Add a title
title(main = "Wordcloud for Amenities", col.main = "black", font.main = 4)
set.seed(1000)
# Define the number of groups and the amount of sample for each
group <- sample(2, nrow(BCN_Accomm),
replace = TRUE,
prob = c(0.4, 0.4))
# training data set with around 60% of the samples
train <- BCN_Accomm[group==1,]
# test data set with around 40% of the samples
test <- BCN_Accomm[group==2,]
# zipcode
new_levels_zipcode <- setdiff(unique(test$zipcode), levels(train$zipcode))
new_levels_zipcode
# Ensure that 'zipcode' in test_reduced has the same levels as in train_reduced
# First, handle any new levels in the test set that are not in the training set
new_levels <- setdiff(unique(test$zipcode), levels(train$zipcode))
# If there are new levels, assign them as 'unknown'
test$zipcode[test$zipcode == 8196] <- "unknown"
test$zipcode[test$zipcode == 8908] <- "unknown"
# Ensure 'zipcode' in the test  has the same levels as the train (including "unknown")
# Use the unique() function to avoid duplicating levels
test$zipcode <- factor(test$zipcode, levels = unique(c(levels(train$zipcode))))
# amenities
new_levels_amenities <- setdiff(unique(test$amenities), levels(train$amenities))
new_levels_amenities # discard, too many
# accommodates
new_levels_accommodates <- setdiff(unique(test$accommodates), levels(train$accommodates))
new_levels_accommodates
#room_type
new_levels_room <- setdiff(unique(test$room_type), levels(train$room_type))
new_levels_room
# availability_30
new_levels_availability <- setdiff(unique(test$availability_30), levels(train$availability_30))
new_levels_availability
# bedrooms
new_levels_bedrooms <- setdiff(unique(test$bedrooms), levels(train$bedrooms))
new_levels_bedrooms
# Map new levels in test as 'unknown'
test$bedrooms[!(test$bedrooms %in% levels(train$bedrooms))] <- "unknown"
test$bedrooms <- factor(test$bedrooms, levels = c(levels(train$bedrooms), "unknown"))
# Ensure Consistent Levels Between Train and Test
test$bedrooms <- factor(test$bedrooms, levels = levels(train$bedrooms))
# Test
new_levels_bedrooms <- setdiff(unique(test$bedrooms), levels(train$bedrooms))
new_levels_bedrooms
# price
new_levels_price <- setdiff(unique(test$price), levels(train$price))
new_levels_price
# Arrange price ranges to avoid memory issues
# Define bin edges for price ranges (e.g., creating 50 equally spaced bins)
bin_edges_train <- seq(min(train$price), max(train$price), length.out = 21)
bin_edges_test <- seq(min(test$price), max(test$price), length.out = 21)
# Create a new 'price' factor by cutting the numeric variable into 50 bins
train$price_grouped <- cut(train$price, breaks = bin_edges_train, labels = FALSE, include.lowest = TRUE)
test$price_grouped <- cut(test$price, breaks = bin_edges_test, labels = FALSE, include.lowest = TRUE)
# the variables in multinomial regression should be converted into a factor
train$price_grouped <- factor(train$price_grouped)
test$price_grouped <- factor(test$price_grouped)
